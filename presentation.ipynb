{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Minatar integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The minatar wrapper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In **standardized *Reinforcement Learning* (RL) environments and benchmarks**, one usually has:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a `reset` method with signature `None -> Tensor` (resets and give 1st observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a `step` method with signature `int -> (Tensor, float, bool, dict)` (takes an action steps into the environment and gives an (observation, reward, done, info) tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a `render` method with signature `None -> None or Tensor` (renders current env state by giving, or not, an image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, **MinAtar does not use this standardized approach**! Rather one has access to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a `reset` method with signature `None -> None` (resets only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- an `act` method with signature `int -> (float, bool)` (steps and gives (reward, done) tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a `state` method with signature `None -> Tensor` (gives an observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a `display_state` method with signature `None -> int(optional)` (renders only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In order to adapt the minatar benchmark to standard RL environments,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and to do as little changes to the original code as possible,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "we implemented a Wrapper class that looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class MinatarWrapper(Environment):\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "            Resets the environment.\n",
    "\n",
    "            Return:\n",
    "                (observation) the first observation.\n",
    "        \"\"\"\n",
    "\n",
    "    def step(self, actions):\n",
    "        \"\"\"\n",
    "            Steps in the environment.\n",
    "\n",
    "            Args:\n",
    "                actions (): the action to take.\n",
    "\n",
    "            Return:\n",
    "                (tensor, float, bool, dict) new observation, reward, done signal and complementary informations.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "    def render(self, time=0, done=False):\n",
    "        \"\"\"\n",
    "            Resets the environment.\n",
    "\n",
    "            Args:\n",
    "                time (int): the number of milliseconds for each frame. if 0, there will be no live animation.\n",
    "                done (bool): tells if the episode is done.\n",
    "\n",
    "            Return:\n",
    "                (Image) the current image of the game.\n",
    "        \"\"\"\n",
    "\n",
    "    def _state(self):\n",
    "        \"\"\"\n",
    "            Reduces the dimensions of the raw observation and normalize it.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "in  `_state`, **reduction** and **normalization** tricks are applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# sums the object channels to have a single image.\n",
    "state = np.sum([state[i] * (i+1) for i in range(state.shape[0])], axis=0)\n",
    "\n",
    "# normalize the image\n",
    "m, M = np.min(state), np.max(state)\n",
    "state = 2 * (state - m) / (M - m) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Environment hyper-definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Breakout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "breakout = Game(env_name=\"minatar:breakout\",\n",
    "                actionSelect=\"softmax\",\n",
    "                input_size=100,\n",
    "                output_size=6,\n",
    "                time_factor=0,\n",
    "                layers=[5, 5],\n",
    "                i_act=np.full(5, 1),\n",
    "                h_act=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                o_act=np.full(1, 1),\n",
    "                weightCap=2.0,\n",
    "                noise_bias=0.0,\n",
    "                output_noise=[False, False, False],\n",
    "                max_episode_length=1000,\n",
    "                in_out_labels=['x', 'x_dot', 'cos(theta)', 'sin(theta)', 'theta_dot',\n",
    "                               'force']\n",
    "                )\n",
    "games[\"minatar:breakout\"] = breakout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Environment hyper-definition\n",
    "### Freeway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "freeway = Game(env_name=\"minatar:freeway\",\n",
    "                actionSelect=\"softmax\",\n",
    "                input_size=100,\n",
    "                output_size=6,\n",
    "                time_factor=0,\n",
    "                layers=[5, 5],\n",
    "                i_act=np.full(5, 1),\n",
    "                h_act=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "                o_act=np.full(1, 1),\n",
    "                weightCap=2.0,\n",
    "                noise_bias=0.0,\n",
    "                output_noise=[False, False, False],\n",
    "                max_episode_length=1000,\n",
    "                in_out_labels=['x', 'x_dot', 'cos(theta)', 'sin(theta)', 'theta_dot',\n",
    "                               'force']\n",
    "                )\n",
    "games[\"minatar:freeway\"] = freeway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameters automatic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "parameters = OrderedDict(\n",
    "    popSize=[64, 200],\n",
    "\n",
    "    prob_addConn=[.025, .1],\n",
    "    prob_addNode=[.015, .06],\n",
    "    prob_crossover=[.7, .9],\n",
    "    prob_enable=[.005, .02],\n",
    "    prob_mutConn=[.7, .9],\n",
    "    prob_initEnable=[.8, 1.],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class RunBuilder:\n",
    "    @staticmethod\n",
    "    def get_runs(parameters):\n",
    "        runs = []\n",
    "        for v in product(*parameters.values()):\n",
    "            runs.append(dict(zip(parameters.keys(), v)))\n",
    "\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "b_fit, b_run = 0, -1\n",
    "for run in RunBuilder.get_runs(parameters):\n",
    "    fitness = run_one_hyp(hyp, run)\n",
    "    if fitness > b_fit:\n",
    "        b_fit = fitness\n",
    "        b_run = run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- the runs where ran on **Breakout** because it is a lot faster to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **fitnesses** where **recorded** for further investigations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "however..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "results were *not good* at all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "the best set of hyperparameters was:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| popSize | prob_addConn | prob_addNode | prob_crossover | prob_enable | prob_mutAct | prob_mutConn | prob_initEnable | budget |\n",
    "| ------- | ------------ | ---- | ---- | ---- | ---- | ---- | ---- | ----- |\n",
    "|    32   |    .025      | .015 |  .7  |  .02 |  .0  |  .9  |  1.  | 50000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and the fitness seen during search was 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So, for final training, we have used the above set of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- run 50000 learning processes 3 times to show statistical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- use the parameters of the above search result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- time spent for Breakout: **~ 2 hours**\n",
    "- final fitness on Breakout: **max of ~ 2.80**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- time spent for Freeway: **~ 21h** (Cumulated)\n",
    "- final fitness on Freeway: **14**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A random breakout agent..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./log/breakout/gifs/3484933263.gif\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "performing around 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "A random freeway agent..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "<img src=\"./357277723.gif\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "almost never reaches the top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The final best breakout agent given by ***NEAT***:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"./log/breakout/gifs/3292025515.gif\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "performing around 2.80 and it takes significantly more time to evaluate such an agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The final best freeway agent given by ***NEAT***:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "<img src=\"./357277723.gif\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "performing around 14 but clearly not very efficient... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Same issue for both problems..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "<img src=\"./Graph.png\" width=\"600\" align=\"center\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "local minimum prevent innovation and diversity, species mechanism isn't efficient enough with our hyperparameters set."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
